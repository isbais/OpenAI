# Prompt Engineering: Estrategias para Mejorar Resultados

## üìã Tabla de Contenidos
- [Introducci√≥n](#introducci√≥n)
- [Generaci√≥n de Texto con la API](#generaci√≥n-de-texto-con-la-api)
- [Elecci√≥n de Modelos](#elecci√≥n-de-modelos)
- [Fundamentos del Prompt Engineering](#fundamentos-del-prompt-engineering)
- [Roles de Mensajes y Seguimiento de Instrucciones](#roles-de-mensajes-y-seguimiento-de-instrucciones)
- [Prompts Reutilizables](#prompts-reutilizables)
- [Formato de Mensajes con Markdown y XML](#formato-de-mensajes-con-markdown-y-xml)
- [Few-Shot Learning](#few-shot-learning)
- [Inclusi√≥n de Informaci√≥n de Contexto](#inclusi√≥n-de-informaci√≥n-de-contexto)
- [Prompting de Modelos GPT-5](#prompting-de-modelos-gpt-5)
- [Prompting de Modelos de Razonamiento](#prompting-de-modelos-de-razonamiento)
- [Pr√≥ximos Pasos](#pr√≥ximos-pasos)
- [Recursos Adicionales](#recursos-adicionales)

## Introducci√≥n

Mejora los resultados con estrategias de **prompt engineering**.

Con la OpenAI API, puedes usar un [large language model](/docs/models) para generar texto desde un prompt, como podr√≠as hacer usando [ChatGPT](https://chatgpt.com). Los modelos pueden generar casi cualquier tipo de respuesta de texto‚Äîcomo c√≥digo, ecuaciones matem√°ticas, datos JSON estructurados, o prosa similar a la humana.

## Generaci√≥n de Texto con la API

Aqu√≠ tienes un ejemplo simple usando la [Chat Completions API](/docs/api-reference/chat).

### Generar Texto desde un Prompt Simple

#### JavaScript
```javascript
import OpenAI from "openai";
const client = new OpenAI();

const completion = await client.chat.completions.create({
    model: "gpt-5",
    messages: [
        {
            role: "user",
            content: "Write a one-sentence bedtime story about a unicorn.",
        },
    ],
});

console.log(completion.choices[0].message.content);
```

#### Python
```python
from openai import OpenAI
client = OpenAI()

completion = client.chat.completions.create(
    model="gpt-5",
    messages=[
        {
            "role": "user",
            "content": "Write a one-sentence bedtime story about a unicorn."
        }
    ]
)

print(completion.choices[0].message.content)
```

#### cURL
```bash
curl "https://api.openai.com/v1/chat/completions" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -d '{
        "model": "gpt-5",
        "messages": [
            {
                "role": "user",
                "content": "Write a one-sentence bedtime story about a unicorn."
            }
        ]
    }'
```

### Estructura de la Respuesta

Un array de contenido generado por el modelo est√° en la propiedad `choices` de la respuesta. En este ejemplo simple, tenemos solo una salida que se ve as√≠:

```json
[
    {
        "index": 0,
        "message": {
            "role": "assistant",
            "content": "Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.",
            "refusal": null
        },
        "logprobs": null,
        "finish_reason": "stop"
    }
]
```

Adem√°s de texto plano, tambi√©n puedes hacer que el modelo devuelva datos estructurados en formato JSON - esta funcionalidad se llama [**Structured Outputs**](/docs/guides/structured-outputs).

## Elecci√≥n de Modelos

Una elecci√≥n clave al generar contenido a trav√©s de la API es qu√© modelo quieres usar - el par√°metro `model` de los ejemplos de c√≥digo anteriores. [Puedes encontrar una lista completa de modelos disponibles aqu√≠](/docs/models). Aqu√≠ hay algunos factores a considerar al elegir un modelo para generaci√≥n de texto.

### Tipos de Modelos

| Tipo de Modelo | Caracter√≠sticas | Casos de Uso |
|----------------|-----------------|--------------|
| **[Reasoning models](/docs/guides/reasoning)** | Generan una cadena de pensamiento interna para analizar el prompt de entrada, y sobresalen en comprensi√≥n de tareas complejas y planificaci√≥n de m√∫ltiples pasos. Tambi√©n son generalmente m√°s lentos y costosos de usar que los modelos GPT. | Tareas complejas, planificaci√≥n, an√°lisis profundo |
| **GPT models** | Son r√°pidos, eficientes en costo y altamente inteligentes, pero se benefician de instrucciones m√°s expl√≠citas sobre c√≥mo realizar tareas. | Generaci√≥n de texto, tareas generales, aplicaciones en tiempo real |
| **Large and small (mini or nano) models** | Ofrecen compensaciones entre velocidad, costo e inteligencia. Los modelos grandes son m√°s efectivos para entender prompts y resolver problemas a trav√©s de dominios, mientras que los modelos peque√±os son generalmente m√°s r√°pidos y baratos de usar. | Optimizaci√≥n de costos, aplicaciones espec√≠ficas |

Cuando tengas dudas, [`gpt-4.1`](/docs/models/gpt-4.1) ofrece una combinaci√≥n s√≥lida de inteligencia, velocidad y eficiencia de costo.

## Fundamentos del Prompt Engineering

**Prompt engineering** es el proceso de escribir instrucciones efectivas para un modelo, de tal manera que genere consistentemente contenido que cumpla con tus requisitos.

Debido a que el contenido generado desde un modelo es no-determin√≠stico, hacer prompting para obtener tu salida deseada es una mezcla de arte y ciencia. Sin embargo, puedes aplicar t√©cnicas y mejores pr√°cticas para obtener buenos resultados consistentemente.

### Consideraciones Importantes

Algunas t√©cnicas de prompt engineering funcionan con cada modelo, como usar roles de mensajes. Pero diferentes tipos de modelos (como reasoning versus GPT models) podr√≠an necesitar ser prompterados de manera diferente para producir los mejores resultados. Incluso diferentes snapshots de modelos dentro de la misma familia podr√≠an producir resultados diferentes.

Para aplicaciones m√°s complejas, recomendamos fuertemente:

- **Fijar tus aplicaciones de producci√≥n** a [model snapshots](/docs/models) espec√≠ficos (como `gpt-4.1-2025-04-14` por ejemplo) para asegurar comportamiento consistente
- **Construir [evals](/docs/guides/evals)** que midan el comportamiento de tus prompts para que puedas monitorear el rendimiento del prompt mientras iteras, o cuando cambies y actualices versiones de modelos

## Roles de Mensajes y Seguimiento de Instrucciones

Puedes proporcionar instrucciones (prompts) al modelo con [diferentes niveles de autoridad](https://model-spec.openai.com/2025-02-12.html#chain_of_command) usando **message roles**.

### Generar Texto con Mensajes Usando Diferentes Roles

#### JavaScript
```javascript
import OpenAI from "openai";
const client = new OpenAI();

const completion = await client.chat.completions.create({
    model: "gpt-5",
    messages: [
        {
            role: "developer",
            content: "Talk like a pirate."
        },
        {
            role: "user",
            content: "Are semicolons optional in JavaScript?",
        },
    ],
});

console.log(completion.choices[0].message);
```

#### Python
```python
from openai import OpenAI
client = OpenAI()

completion = client.chat.completions.create(
    model="gpt-5",
    reasoning={"effort": "low"},
    messages=[
        {
            "role": "developer",
            "content": "Talk like a pirate."
        },
        {
            "role": "user",
            "content": "Are semicolons optional in JavaScript?"
        }
    ]
)

print(completion.choices[0].message.content)
```

#### cURL
```bash
curl "https://api.openai.com/v1/chat/completions" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -d '{
        "model": "gpt-5",
        "messages": [
            {
                "role": "developer",
                "content": "Talk like a pirate."
            },
            {
                "role": "user",
                "content": "Are semicolons optional in JavaScript?"
            }
        ]
    }'
```

### Jerarqu√≠a de Roles

La [OpenAI model spec](https://model-spec.openai.com/2025-02-12.html#chain_of_command) describe c√≥mo nuestros modelos dan diferentes niveles de prioridad a mensajes con diferentes roles.

| Rol | Descripci√≥n | Prioridad |
|-----|-------------|-----------|
| **developer** | Los mensajes developer son instrucciones proporcionadas por el desarrollador de la aplicaci√≥n, priorizadas antes que los mensajes de usuario. | M√°s alta |
| **user** | Los mensajes user son instrucciones proporcionadas por un usuario final, priorizadas despu√©s de los mensajes developer. | Media |
| **assistant** | Los mensajes generados por el modelo tienen el rol assistant. | Autom√°tica |

Una conversaci√≥n de m√∫ltiples turnos puede consistir en varios mensajes de estos tipos, junto con otros tipos de contenido proporcionados tanto por ti como por el modelo. Aprende m√°s sobre [manejo del estado de conversaci√≥n aqu√≠](/docs/guides/conversation-state).

### Analog√≠a de Programaci√≥n

Podr√≠as pensar en los mensajes `developer` y `user` como una funci√≥n y sus argumentos en un lenguaje de programaci√≥n:

- Los mensajes `developer` proporcionan las reglas del sistema y la l√≥gica de negocio, como una definici√≥n de funci√≥n.
- Los mensajes `user` proporcionan entradas y configuraci√≥n a las que se aplican las instrucciones del mensaje developer, como argumentos a una funci√≥n.

## Prompts Reutilizables

En el dashboard de OpenAI, puedes desarrollar [prompts](/chat/edit) reutilizables que puedes usar en solicitudes de API, en lugar de especificar el contenido de prompts en c√≥digo. De esta manera, puedes construir y evaluar tus prompts m√°s f√°cilmente, y desplegar versiones mejoradas de tus prompts sin cambiar tu c√≥digo de integraci√≥n.

Los prompts reutilizables est√°n actualmente soportados solo en la [Responses API](/docs/guides/text?api-mode=responses#reusable-prompts). No est√°n disponibles en la Chat Completions API.

## Formato de Mensajes con Markdown y XML

Al escribir mensajes `developer` y `user`, puedes ayudar al modelo a entender los l√≠mites l√≥gicos de tu prompt y datos de contexto usando una combinaci√≥n de formato [Markdown](https://commonmark.org/help/) y [XML tags](https://www.w3.org/TR/xml/).

### Estructura de un Mensaje Developer

Los headers y listas de Markdown pueden ser √∫tiles para marcar secciones distintas de un prompt, y para comunicar jerarqu√≠a al modelo. Tambi√©n pueden potencialmente hacer tus prompts m√°s legibles durante el desarrollo. Los XML tags pueden ayudar a delinear d√≥nde comienza y termina una pieza de contenido (como un documento de soporte usado para referencia). Los atributos XML tambi√©n pueden usarse para definir metadata sobre contenido en el prompt que puede ser referenciado por tus instrucciones.

En general, un mensaje developer contendr√° las siguientes secciones, usualmente en este orden:

1. **Identity:** Describe el prop√≥sito, estilo de comunicaci√≥n y objetivos de alto nivel del assistant.
2. **Instructions:** Proporciona gu√≠a al modelo sobre c√≥mo generar la respuesta que quieres. ¬øQu√© reglas debe seguir? ¬øQu√© debe hacer el modelo, y qu√© nunca debe hacer el modelo?
3. **Examples:** Proporciona ejemplos de posibles entradas, junto con la salida deseada del modelo.
4. **Context:** Da al modelo cualquier informaci√≥n adicional que pueda necesitar para generar una respuesta.

### Ejemplo de Prompt Estructurado

```text
# Identity

You are coding assistant that helps enforce the use of snake case 
variables in JavaScript code, and writing code that will run in 
Internet Explorer version 6.

# Instructions

* When defining variables, use snake case names (e.g. my_variable) 
  instead of camel case names (e.g. myVariable).
* To support old browsers, declare variables using the older 
  "var" keyword.
* Do not give responses with Markdown formatting, just return 
  the code as requested.

# Examples

<user_query>
How do I declare a string variable for a first name?
</user_query>

<assistant_response>
var first_name = "Anna";
</assistant_response>
```

### Solicitud de API

```javascript
import fs from "fs/promises";
import OpenAI from "openai";
const client = new OpenAI();

const instructions = await fs.readFile("prompt.txt", "utf-8");

const response = await client.responses.create({
    model: "gpt-5",
    instructions,
    input: "How would I declare a variable for a last name?",
});

console.log(response.output_text);
```

### Ahorro en Costo y Latencia con Prompt Caching

Al construir un mensaje, deber√≠as intentar mantener el contenido que esperas usar una y otra vez en tus solicitudes de API al **inicio** de tu prompt, **y** entre los primeros par√°metros de API que pasas en el cuerpo JSON de la solicitud a [Chat Completions](/docs/api-reference/chat) o [Responses](/docs/api-reference/responses). Esto te permite maximizar los ahorros de costo y latencia del [prompt caching](/docs/guides/prompt-caching).

## Few-Shot Learning

El **few-shot learning** te permite dirigir un large language model hacia una nueva tarea incluyendo un pu√±ado de ejemplos de entrada/salida en el prompt, en lugar de [fine-tuning](/docs/guides/model-optimization) el modelo. El modelo impl√≠citamente "capta" el patr√≥n de esos ejemplos y lo aplica a un prompt.

### Ejemplo de Few-Shot Learning

```text
# Identity

You are a helpful assistant that labels short product reviews as
Positive, Negative, or Neutral.

# Instructions

* Only output a single word in your response with no additional formatting
  or commentary.
* Your response should only be one of the words "Positive", "Negative", or
  "Neutral" depending on the sentiment of the product review you are given.

# Examples

<product_review id="example-1">
I absolutely love this headphones ‚Äî sound quality is amazing!
</product_review>

<assistant_response id="example-1">
Positive
</assistant_response>

<product_review id="example-2">
Battery life is okay, but the ear pads feel cheap.
</product_review>

<assistant_response id="example-2">
Neutral
</assistant_response>

<product_review id="example-3">
Terrible customer service, I'll never buy from them again.
</product_review>

<assistant_response id="example-3">
Negative
</assistant_response>
```

## Inclusi√≥n de Informaci√≥n de Contexto

A menudo es √∫til incluir informaci√≥n de contexto adicional que el modelo puede usar para generar una respuesta dentro del prompt que le das al modelo. Hay algunas razones comunes por las que podr√≠as hacer esto:

- Para dar al modelo acceso a datos propietarios, o cualquier otro dato fuera del dataset en el que el modelo fue entrenado.
- Para restringir la respuesta del modelo a un conjunto espec√≠fico de recursos que has determinado ser√°n m√°s beneficiosos.

### Retrieval-Augmented Generation (RAG)

La t√©cnica de agregar contexto relevante adicional a la solicitud de generaci√≥n del modelo a veces se llama **retrieval-augmented generation (RAG)**. Puedes agregar contexto adicional al prompt de muchas maneras diferentes, desde consultar una base de datos vectorial e incluir el texto que obtienes de vuelta en un prompt, o usando la [file search tool](/docs/guides/tools-file-search) integrada de OpenAI para generar contenido basado en documentos subidos.

### Planificaci√≥n para la Ventana de Contexto

Los modelos solo pueden manejar cierta cantidad de datos dentro del contexto que consideran durante una solicitud de generaci√≥n. Este l√≠mite de memoria se llama **context window**, que se define en t√©rminos de [tokens](https://blogs.nvidia.com/blog/ai-tokens-explained) (fragmentos de datos que pasas, desde texto hasta im√°genes).

Los modelos tienen diferentes tama√±os de context window desde el rango bajo de 100k hasta un mill√≥n de tokens para modelos GPT-4.1 m√°s nuevos. [Consulta la documentaci√≥n de modelos](/docs/models) para tama√±os espec√≠ficos de context window por modelo.

## Prompting de Modelos GPT-5

Los modelos GPT como [`gpt-5`](/docs/models/gpt-5) se benefician de instrucciones precisas que proporcionan expl√≠citamente la l√≥gica y datos requeridos para completar la tarea en el prompt. GPT-5 en particular es altamente controlable y receptivo a prompts bien especificados.

### Mejores Pr√°cticas para GPT-5

#### üñ•Ô∏è Coding

El prompting de GPT-5 para tareas de coding es m√°s efectivo cuando se siguen algunas mejores pr√°cticas: definir el rol del agente, hacer cumplir el uso estructurado de herramientas con ejemplos, requerir testing exhaustivo para correcci√≥n, y establecer est√°ndares de Markdown para salida limpia.

**Gu√≠a expl√≠cita de rol y flujo de trabajo**: Enmarca el modelo como un agente de software engineering con responsabilidades bien definidas. Proporciona instrucciones claras para usar herramientas como `functions.run` para tareas de c√≥digo, y especifica cu√°ndo no usar ciertos modos.

**Testing y validaci√≥n**: Instruye al modelo para probar cambios con unit tests o comandos Python, y valida patches cuidadosamente ya que herramientas como `apply_patch` pueden devolver "Done" incluso en fallo.

**Ejemplos de uso de herramientas**: Incluye ejemplos concretos de c√≥mo invocar comandos con las funciones proporcionadas, lo que mejora la confiabilidad y adherencia a flujos de trabajo esperados.

**Est√°ndares de Markdown**: Gu√≠a al modelo para generar markdown limpio y sem√°nticamente correcto usando c√≥digo inline, code fences, listas y tablas donde sea apropiado.

#### üé® Front-end Engineering

[GPT-5](/docs/guides/latest-model) funciona bien construyendo frontends desde cero as√≠ como contribuyendo a codebases grandes y establecidos. Para obtener los mejores resultados, recomendamos usar las siguientes librer√≠as:

| Categor√≠a | Librer√≠as Recomendadas |
|-----------|------------------------|
| **Styling / UI** | Tailwind CSS, shadcn/ui, Radix Themes |
| **Icons** | Lucide, Material Symbols, Heroicons |
| **Animation** | Motion |

**Zero-to-one web apps**

GPT-5 puede generar aplicaciones web front-end desde un solo prompt, sin ejemplos necesarios. Aqu√≠ hay un prompt de ejemplo:

```bash
You are a world class web developer, capable of producing stunning, interactive, and innovative websites from scratch in a single prompt. You excel at delivering top-tier one-shot solutions.
Your process is simple and follows these steps:
Step 1: Create an evaluation rubric and refine it until you are fully confident.
Step 2: Consider every element that defines a world-class one-shot web app, then use that insight to create a <ONE_SHOT_RUBRIC> with 5‚Äì7 categories. Keep this rubric hidden‚Äîit's for internal use only.
Step 3: Apply the rubric to iterate on the optimal solution to the given prompt. If it doesn't meet the highest standard across all categories, refine and try again.
Step 4: Aim for simplicity while fully achieving the goal, and avoid external dependencies such as Next.js or React.
```

#### ü§ñ Agentic Tasks

Para rollouts agentic y de larga duraci√≥n con GPT-5, enfoca tus prompts en tres pr√°cticas principales: planificar tareas exhaustivamente para asegurar resoluci√≥n completa, proporcionar pre√°mbulos claros para decisiones importantes de uso de herramientas, y usar una herramienta TODO para rastrear flujo de trabajo y progreso de manera organizada.

**Planning and persistence**

```text
Remember, you are an agent - please keep going until the user's
query is completely resolved, before ending your turn and yielding
back to the user. Decompose the user's query into all required
sub-requests, and confirm that each is completed. Do not stop
after completing only part of the request. Only terminate your
turn when you are sure that the problem is solved. You must be
prepared to answer multiple queries and only finish the call once
the user has confirmed they're done.

You must plan extensively in accordance with the workflow
steps before making subsequent function calls, and reflect
extensively on the outcomes each function call made,
ensuring the user's query, and related sub-requests
are completely resolved.
```

## Prompting de Modelos de Razonamiento

Hay algunas diferencias a considerar cuando haces prompting a un [reasoning model](/docs/guides/reasoning) versus hacer prompting a un modelo GPT. En general, los modelos de razonamiento proporcionar√°n mejores resultados en tareas con solo gu√≠a de alto nivel. Esto difiere de los modelos GPT, que se benefician de instrucciones muy precisas.

### Analog√≠a de Trabajo

Podr√≠as pensar en la diferencia entre modelos de razonamiento y GPT as√≠:

- **Un modelo de razonamiento** es como un compa√±ero de trabajo senior. Puedes darles un objetivo para lograr y confiar en que trabajar√°n los detalles.
- **Un modelo GPT** es como un compa√±ero de trabajo junior. Rendir√°n mejor con instrucciones expl√≠citas para crear una salida espec√≠fica.

Para m√°s informaci√≥n sobre mejores pr√°cticas cuando uses modelos de razonamiento, [consulta esta gu√≠a](/docs/guides/reasoning-best-practices).

## Pr√≥ximos Pasos

Ahora que conoces los fundamentos de entradas y salidas de texto, podr√≠as querer revisar uno de estos recursos a continuaci√≥n.

### Recursos Recomendados

- **[Build a prompt in the Playground](/chat/edit)** - Usa el Playground para desarrollar e iterar en prompts
- **[Generate JSON data with Structured Outputs](/docs/guides/structured-outputs)** - Asegura que los datos JSON emitidos desde un modelo se conformen a un JSON schema
- **[Full API reference](/docs/api-reference/responses)** - Revisa todas las opciones para generaci√≥n de texto en la referencia de API

## Recursos Adicionales

Para m√°s inspiraci√≥n, visita el [OpenAI Cookbook](https://cookbook.openai.com), que contiene c√≥digo de ejemplo y tambi√©n enlaces a recursos de terceros como:

### üìö Recursos de Prompting

| Categor√≠a | Descripci√≥n | Enlaces |
|-----------|-------------|---------|
| **Prompting libraries & tools** | Librer√≠as y herramientas para prompt engineering | [Ver recursos](https://cookbook.openai.com/related_resources#prompting-libraries--tools) |
| **Prompting guides** | Gu√≠as y tutoriales de prompting | [Ver recursos](https://cookbook.openai.com/related_resources#prompting-guides) |
| **Video courses** | Cursos en video sobre prompt engineering | [Ver recursos](https://cookbook.openai.com/related_resources#video-courses) |
| **Papers on advanced prompting** | Papers acad√©micos sobre prompting avanzado para mejorar razonamiento | [Ver recursos](https://cookbook.openai.com/related_resources#papers-on-advanced-prompting-to-improve-reasoning) |

---

> **Nota**: El prompt engineering es una habilidad que mejora con la pr√°ctica. Experimenta con diferentes t√©cnicas y encuentra lo que funciona mejor para tus casos de uso espec√≠ficos.

### Gu√≠as Espec√≠ficas Recomendadas

- **[GPT-5 prompting guide](https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide)** - Obt√©n el m√°ximo provecho del prompting de GPT-5
- **[Frontend engineering cookbook](https://cookbook.openai.com/examples/gpt-5/gpt-5_frontend)** - Gu√≠a espec√≠fica para desarrollo frontend

---

*Esta gu√≠a se actualiza regularmente con las mejores pr√°cticas emergentes en prompt engineering.*
