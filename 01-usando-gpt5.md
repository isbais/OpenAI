# Gu칤a de GPT-5: El Modelo M치s Inteligente de OpenAI

## 游늶 Tabla de Contenidos
- [Introducci칩n](#introducci칩n)
- [Caracter칤sticas Principales](#caracter칤sticas-principales)
- [Modelos Disponibles](#modelos-disponibles)
- [Nuevas Funcionalidades de la API](#nuevas-funcionalidades-de-la-api)
- [Gu칤a de Migraci칩n](#gu칤a-de-migraci칩n)
- [Mejores Pr치cticas](#mejores-pr치cticas)
- [Preguntas Frecuentes](#preguntas-frecuentes)

## Introducci칩n

GPT-5 es nuestro modelo m치s inteligente hasta la fecha, entrenado para ser especialmente competente en:

- **Generaci칩n de c칩digo**, correcci칩n de bugs y refactoring
- **Seguimiento de instrucciones**
- **Contexto largo** y llamadas a herramientas (tool calling)

Esta gu칤a cubre las caracter칤sticas clave de la familia de modelos GPT-5 y c칩mo aprovechar al m치ximo GPT-5.

### 游 Explorar Ejemplos de C칩digo

Haz clic a trav칠s de algunas aplicaciones de demostraci칩n generadas completamente con un solo prompt de GPT-5, sin escribir ning칰n c칩digo manualmente.

[Ver ejemplos en la plataforma OpenAI](https://platform.openai.com/docs/guides/latest-model?gallery=open)

## Caracter칤sticas Principales

GPT-5 est치 dise침ado espec칤ficamente para sobresalir en:
- **Coding** y frontend engineering
- **Tool-calling** para tareas agentic
- **Razonamiento complejo** y conocimiento amplio del mundo

## Modelos Disponibles

Hay tres modelos en la serie GPT-5. En general, `gpt-5` es mejor para tus tareas m치s complejas que requieren conocimiento amplio del mundo. Los modelos m치s peque침os `mini` y `nano` sacrifican algo de conocimiento general del mundo por menor costo y menor latencia. Los modelos peque침os tender치n a funcionar mejor para tareas m치s bien definidas.

### Comparaci칩n de Modelos

| Variante | Mejor para |
|----------|------------|
| `gpt-5` | Razonamiento complejo, conocimiento amplio del mundo, y tareas agentic con mucho c칩digo o de m칰ltiples pasos |
| `gpt-5-mini` | Razonamiento y chat optimizado en costo; equilibra velocidad, costo y capacidad |
| `gpt-5-nano` | Tareas de alto rendimiento, especialmente seguimiento simple de instrucciones o clasificaci칩n |

## Nuevas Funcionalidades de la API

Junto con GPT-5, estamos introduciendo algunos nuevos par치metros y funcionalidades de API dise침ados para dar a los desarrolladores m치s control y flexibilidad:

- **Control de verbosidad** (verbosity)
- **Opci칩n de esfuerzo de razonamiento m칤nimo** (minimal reasoning effort)
- **Herramientas personalizadas** (custom tools)
- **Lista de herramientas permitidas** (allowed tools list)

### Esfuerzo de Razonamiento M칤nimo

El par치metro `reasoning.effort` controla cu치ntos tokens de razonamiento genera el modelo antes de producir una respuesta. Los modelos de razonamiento anteriores como `o3` solo soportaban `low`, `medium` y `high`: `low` favorec칤a la velocidad y menos tokens, mientras que `high` favorec칤a un razonamiento m치s exhaustivo.

La nueva configuraci칩n `minimal` produce muy pocos tokens de razonamiento para casos donde necesitas el tiempo m치s r치pido posible hasta el primer token. A menudo vemos mejor rendimiento cuando el modelo puede producir algunos tokens cuando es necesario versus ninguno. El valor por defecto es `medium`.

La configuraci칩n `minimal` funciona especialmente bien en escenarios de coding y seguimiento de instrucciones, adhiri칠ndose estrechamente a las direcciones dadas. Sin embargo, puede requerir prompting para actuar de manera m치s proactiva. Para mejorar la calidad del razonamiento del modelo, incluso con esfuerzo m칤nimo, an칤malo a "pensar" o esbozar sus pasos antes de responder.

#### Ejemplo de C칩digo

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input="쮺u치nto oro se necesitar칤a para recubrir la Estatua de la Libertad con una capa de 1mm?",
    reasoning={
        "effort": "minimal"
    }
)

print(response)
```

### Verbosidad

La verbosidad determina cu치ntos tokens de salida se generan. Reducir el n칰mero de tokens disminuye la latencia general. Mientras que el enfoque de razonamiento del modelo se mantiene mayormente igual, el modelo encuentra formas de responder de manera m치s concisa, lo que puede mejorar o disminuir la calidad de la respuesta, dependiendo de tu caso de uso.

#### Escenarios de Verbosidad

| Nivel | Mejor para |
|-------|------------|
| **Alta verbosidad** | Cuando necesitas que el modelo proporcione explicaciones exhaustivas de documentos o realice refactoring extenso de c칩digo |
| **Baja verbosidad** | Mejor para situaciones donde quieres respuestas concisas o generaci칩n simple de c칩digo, como consultas SQL |

Los modelos anteriores a GPT-5 han usado verbosidad `medium` por defecto. Con GPT-5, hacemos esta opci칩n configurable como `high`, `medium` o `low`.

Al generar c칩digo, los niveles de verbosidad `medium` y `high` producen c칩digo m치s largo y estructurado con explicaciones en l칤nea, mientras que la verbosidad `low` produce c칩digo m치s corto y conciso con comentarios m칤nimos.

#### Ejemplo de Control de Verbosidad

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input="쮺u치l es la respuesta a la pregunta 칰ltima sobre la vida, el universo y todo?",
    text={
        "verbosity": "low"
    }
)

print(response)
```

### Herramientas Personalizadas

Con GPT-5, estamos introduciendo una nueva capacidad llamada **custom tools**, que permite a los modelos enviar cualquier texto sin formato como entrada de tool call, pero a칰n restringir las salidas si se desea.

#### Entradas de Formato Libre

Define tu herramienta con `type: custom` para permitir que los modelos env칤en entradas de texto plano directamente a tus herramientas, en lugar de estar limitados a JSON estructurado. El modelo puede enviar cualquier texto sin formato: c칩digo, consultas SQL, comandos de shell, archivos de configuraci칩n o prosa extensa directamente a tu herramienta.

```json
{
    "type": "custom",
    "name": "code_exec",
    "description": "Ejecuta c칩digo Python arbitrario"
}
```

#### Restricci칩n de Salidas

GPT-5 soporta **context-free grammars (CFGs)** para custom tools, permiti칠ndote proporcionar una gram치tica Lark para restringir las salidas a una sintaxis o DSL espec칤fica. Adjuntar una CFG (por ejemplo, una gram치tica SQL o DSL) asegura que el texto del asistente coincida con tu gram치tica.

#### Mejores Pr치cticas para Custom Tools

1. **Escribe descripciones de herramientas concisas y expl칤citas**. El modelo elige qu칠 enviar bas치ndose en tu descripci칩n; declara claramente si quieres que siempre llame a la herramienta.

2. **Valida las salidas en el lado del servidor**. Las cadenas de formato libre son poderosas pero requieren salvaguardas contra inyecci칩n o comandos inseguros.

### Herramientas Permitidas

El par치metro `allowed_tools` bajo `tool_choice` en la API de Respuestas de GPT-5 te permite pasar N definiciones de herramientas pero restringir el modelo a solo M (< N) de ellas. Lista tu toolkit completo en `tools`, y luego usa un bloque `allowed_tools` para nombrar el subconjunto y especificar un modo: `auto` (el modelo puede elegir cualquiera de esos) o `required` (el modelo debe invocar uno).

#### Comparaci칩n de Herramientas

| Aspecto | Standard Tools | Allowed Tools |
|---------|----------------|---------------|
| **Universo del modelo** | Todas las herramientas listadas bajo `"tools": [...]` | Solo el subconjunto bajo `"tools": [...]` en `tool_choice` |
| **Invocaci칩n de herramientas** | El modelo puede o no llamar cualquier herramienta | Modelo restringido a (o requerido para llamar) herramientas elegidas |
| **Prop칩sito** | Declarar capacidades disponibles | Restringir qu칠 capacidades se usan realmente |

#### Ejemplo de Configuraci칩n

```json
{
  "tool_choice": {
    "type": "allowed_tools",
    "mode": "auto",
    "tools": [
      { "type": "function", "name": "get_weather" },
      { "type": "mcp", "server_label": "deepwiki" },
      { "type": "image_generation" }
    ]
  }
}
```

### Pre치mbulos (Preambles)

Los pre치mbulos son explicaciones breves y visibles para el usuario que GPT-5 genera antes de invocar cualquier herramienta o funci칩n, esbozando su intenci칩n o plan (por ejemplo, "por qu칠 estoy llamando a esta herramienta"). Aparecen despu칠s del chain-of-thought y antes de la llamada real a la herramienta, proporcionando transparencia en el razonamiento del modelo y mejorando la depuraci칩n, confianza del usuario y controlabilidad granular.

Para habilitar pre치mbulos, agrega una instrucci칩n del sistema o desarrollador, por ejemplo: "Antes de llamar a una herramienta, explica por qu칠 la est치s llamando". GPT-5 antepone una justificaci칩n concisa a cada llamada de herramienta especificada.

## Gu칤a de Migraci칩n

GPT-5 es nuestro mejor modelo hasta ahora, y funciona mejor con la **Responses API**, que soporta pasar chain of thought (CoT) entre turnos.

### Migrando de Otros Modelos a GPT-5

Vemos inteligencia mejorada porque la Responses API puede pasar el CoT del turno anterior al modelo. Esto lleva a menos tokens de razonamiento generados, mayores tasas de cache hit y menor latencia.

#### Recomendaciones de Migraci칩n

| Modelo Original | Reemplazo Recomendado | Configuraci칩n Inicial |
|-----------------|----------------------|----------------------|
| `o3` | `gpt-5` con reasoning `medium` o `high` | Comenzar con reasoning `medium` y ajuste de prompts |
| `gpt-4.1` | `gpt-5` con reasoning `minimal` o `low` | Comenzar con reasoning `minimal` |
| `o4-mini` o `gpt-4.1-mini` | `gpt-5-mini` con ajuste de prompts | Ajuste de prompts requerido |
| `gpt-4.1-nano` | `gpt-5-nano` con ajuste de prompts | Ajuste de prompts requerido |

### Migrando de Chat Completions a Responses API

La mayor diferencia, y raz칩n principal para migrar de Chat Completions a la Responses API para GPT-5, es el soporte para pasar chain of thought (CoT) entre turnos.

#### Comparaci칩n de APIs

| Par치metro | Responses API | Chat Completions |
|-----------|---------------|------------------|
| **Esfuerzo de razonamiento** | `reasoning.effort` | No disponible |
| **Verbosidad** | `text.verbosity` | No disponible |
| **Custom tools** | `tools` con `type: "custom"` | Limitado |

## Mejores Pr치cticas

### Optimizador de Prompts de GPT-5

Crea el prompt perfecto para GPT-5 en el dashboard.

### GPT-5 es un Modelo de Razonamiento

Los modelos de razonamiento como GPT-5 descomponen problemas paso a paso, produciendo una cadena de pensamiento interna que codifica su razonamiento. Para maximizar el rendimiento, pasa estos elementos de razonamiento de vuelta al modelo: esto evita re-razonamiento y mantiene las interacciones m치s cerca de la distribuci칩n de entrenamiento del modelo.

En conversaciones de m칰ltiples turnos, pasar un `previous_response_id` autom치ticamente hace disponibles los elementos de razonamiento anteriores. Esto es especialmente importante cuando se usan herramientas, por ejemplo, cuando una llamada de funci칩n requiere un viaje de ida y vuelta extra.

### Recursos Adicionales

- [Gu칤a de prompting de GPT-5](#)
- [Gu칤a de frontend de GPT-5](#)
- [Gu칤a de nuevas funcionalidades de GPT-5](#)
- [Cookbook sobre modelos de razonamiento](#)
- [Comparaci칩n de Responses API versus Chat Completions](#)

## Preguntas Frecuentes

### 쮺칩mo se integran estos modelos en ChatGPT?

En ChatGPT, hay dos modelos: `gpt-5-chat` y `gpt-5-thinking`. Ofrecen capacidades de razonamiento y razonamiento m칤nimo, con una capa de enrutamiento que selecciona el mejor modelo bas치ndose en la pregunta del usuario. Los usuarios tambi칠n pueden invocar razonamiento directamente a trav칠s de la UI de ChatGPT.

### 쮼stos modelos ser치n soportados en Codex?

S칤, `gpt-5` estar치 disponible en Codex y Codex CLI.

### 쮺u치l es el plan de deprecaci칩n para modelos anteriores?

Cualquier deprecaci칩n de modelos se publicar치 en nuestra p치gina de deprecaciones. Enviaremos aviso anticipado de cualquier deprecaci칩n de modelos.

---

> **Nota**: Para una visi칩n m치s detallada de todas estas nuevas funcionalidades, consulta el cookbook adjunto.